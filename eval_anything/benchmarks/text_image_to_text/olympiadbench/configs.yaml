# ============================================
# 评测配置：
#   - 数据集hf路径
#   - 数据集split
#   - 数据集size
#   - 数据集模态
#   - 评测方式（multiple choice / generation / ...）
#   - 评测指标（accuracy / ...）
#   - 是否支持few_shot
#   - 选项编号形式（ABCD或1234...），判断对错时的标识(true/false或者1/0...)
# ============================================
dataset:
  name: olympiadbench
  path: Hothan/OlympiadBench
  split: train
  size: 
  modality: text-image-to-text
  fewshot_data_path: null
  fewshot_data_name: null
  fewshot_data_split: null
  cot_fewshot_data_path: null
  cot_fewshot_data_name: null
  cot_fewshot_data_split: null
  max_shot: 0
  default_task_list: ["OE_MM_maths_en_COMP", "OE_MM_maths_zh_CEE", "OE_MM_maths_zh_COMP","OE_MM_physics_en_COMP", "OE_MM_physics_zh_CEE", "OE_TO_maths_en_COMP","OE_TO_maths_zh_CEE", "OE_TO_maths_zh_COMP", "OE_TO_physics_en_COMP","OE_TO_physics_zh_CEE",]
task_defaults: &task_defaults
  type: MultiChoice
  question_key: question
  answer_key: options
  ground_truth_key: answer
  candidate_labels: ["A", "B", "C", "D", "E"]
  avalable_evaluate_tools: ["match_multi-choice_and_open-ended"]
task: 
  - name: OE_MM_maths_en_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_MM_maths_zh_CEE
    data_files: null
    <<: *task_defaults
  - name: OE_MM_maths_zh_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_MM_physics_en_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_MM_physics_zh_CEE
    data_files: null
    <<: *task_defaults
  - name: OE_TO_maths_en_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_TO_maths_zh_CEE
    data_files: null
    <<: *task_defaults
  - name: OE_TO_maths_zh_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_TO_physics_en_COMP
    data_files: null
    <<: *task_defaults
  - name: OE_TO_physics_zh_CEE
    data_files: null
    <<: *task_defaults
answer_extractor:
  - name: match_multi-choice_and_open-ended
    function: regex_match_latex_math
    args:
      match_index: -1   # Index for multiple choice
metrics:
  - name: accuracy
    function: accuracy
    args:
overall_metrics:
  - name: average
    function: average_across_tasks
    args:
      null
  